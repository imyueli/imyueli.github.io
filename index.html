<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Dr. Yue Li, HCI and XR Researcher </title> <meta name="author" content="Yue Li"> <meta name="description" content="Dr. Yue Li's personal website. "> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%8C%9D&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://imyueli.github.io/"> <script src="/assets/js/theme.js?v=561b4de9fbf7bf604dafd8b6fb3f1ae5"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">About <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">Teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">Resume </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> Dr. Yue Li, HCI and XR Researcher </h1> <p class="desc">BSc (Hons) in CS, PhD in CS, FHEA. HCI &amp; XR Researcher <a href="https://scholar.xjtlu.edu.cn/en/persons/YueLi/" rel="external nofollow noopener" target="_blank">@XJTLU</a>.</p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/yue_li-480.webp 480w,/assets/img/yue_li-800.webp 800w,/assets/img/yue_li-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img/yue_li.jpg?v=1ed5ad8f6af129c45495667d5d62b34a" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="yue_li.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"> <p>SD457, Science Building</p> <p>Xi'an Jiaotong-Liverpool University</p> <p>Suzhou, China</p> <p>215123</p> </div> </div> <div class="clearfix"> <p>I am an Associate Professor at the Department of Computing, School of Advanced Technology, Xi‚Äôan Jiaotong-Liverpool University. I lead the <a href="https://hiherlab.github.io/" rel="external nofollow noopener" target="_blank">Heritage, Edutainment, and Reality Laboratory (HER Lab)</a>.</p> <p>My research interest is in the field of <strong>Human-Computer Interaction (HCI)</strong>, with particular emphasis on <strong>Extended Reality (XR)</strong> technologies. I have been actively involved in research related to the design, evaluation, and application of Virtual Reality (VR) and Augmented Reality (AR) in cultural heritage and education.</p> <p>I received my PhD degree from the <strong>University of Nottingham</strong> in 2020 with the Postgraduate Award. During my PhD study, I worked at the NVIDIA Joint-Lab on Mixed Reality in Ningbo, China and the Mixed Reality Lab in Nottingham, UK.</p> <p>I have received several prestigious research grants, including the Young Scientist Programme of the <strong>National Natural Science Foundation of China (NSFC)</strong> and the General Programme of the <strong>Natural Science Foundation of the Jiangsu Higher Education Institutions of China</strong>. My scholarly contributions are published in esteemed international journals and conferences such as IEEE TVCG, ACM ToCHI, IJHCI, ACM JoCCH, IEEE VR, IEEE ISMAR, ACM CHI, and so on. I serve as the China Country Representative at the IFIP Technical Committee on Human‚ÄìComputer Interaction (TC13). I also hold executive member roles in the CCF Technical Committees of HCI and VR and Visualization. I am a professional member of BCS, ACM, IEEE, and IET.</p> <p>My commitment to the field is underscored by my regular service and engagement as an editorial board member, program committee member, and reviewer for international journals and conferences. Currently I am an <strong>Associate Editor</strong> of <a href="https://academic.oup.com/iwc" rel="external nofollow noopener" target="_blank">Interacting with Computers</a> and <a href="https://direct.mit.edu/pvar" rel="external nofollow noopener" target="_blank">PRESENCE: Virtual and Augmented Reality</a>. I served as the Online Experience Co-Chair in IEEE VR 2023, the Student Competition Co-Chair in IEEE ISMAR 2023, the Poster Co-Chair in IEEE AIxVR 2024, and the XR Gallery Co-Chair in IEEE VR 2026.</p> </div> <h2> <a href="/news/" style="color: inherit">News</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Dec 18, 2025</th> <td> Attend the 5th MEGA International Creative Media Festival &amp; Launch Ceremony of Immersive Dome Cinema. Thanks Prof. Qian Liu for the invitation. </td> </tr> <tr> <th scope="row" style="width: 20%">Dec 05, 2025</th> <td> I am promoted to Associate Professor. <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> </td> </tr> <tr> <th scope="row" style="width: 20%">Nov 15, 2025</th> <td> Attending CCF YOCSEF Forum in Zibo, Jinan. I gave a talk - <strong>XR and AI Empowered Digital Heritage Innovation: A Case Study of the Relics Arhat Monastery and Twin Pagoda in Suzhou</strong>. Thanks Prof. Huiyu Li for the invitation. </td> </tr> <tr> <th scope="row" style="width: 20%">Nov 02, 2025</th> <td> Attending ICXR 2025 in Qingdao with my PhD student Bingqing Chen. We presented our paper - <strong>Voice of Artifacts</strong> <a class="citation" href="#Chen2025VoiceArtifactsEvaluatinga">(Chen et al., 2025)</a>. </td> </tr> <tr> <th scope="row" style="width: 20%">Oct 13, 2025</th> <td> üèÜ Our paper, <strong>XR Exhibit+</strong> <a class="citation" href="#Zeng2025XRExhibitAIEnhanced">(Zeng et al., 2025)</a>, won the <strong>Best Paper Award</strong> at UbiComp UbiSense 2025! Congratulations to Gengyuan and the team! </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">Selected publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="Chng2020EffectsVREnvironments" class="col-sm-8"> <div class="title">The Effects of VR Environments on the Acceptance, Experience, and Expectations of Cultural Heritage Learning</div> <div class="author"> Eugene Ch‚Äông, <em>Yue Li</em>, Shengdan Cai, and Fui-Theng Leow </div> <div class="periodical"> <em>Journal on Computing and Cultural Heritage</em>, Feb 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3352933" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> </div> <div class="abstract hidden"> <p>This article attempts to understand how present Virtual Reality (VR) environments can contribute to enhancing the communication of cultural heritage by providing an experience of the past that is acceptable for the younger generation and how museums and cultural institutions should adopt and use such technologies. Aspects of acceptance, experience, and expectation of VR with the underlying values are not well understood but are important for the sustainability of the communication of cultural heritage as a bequest to future generations. We conducted a combined quantitative‚Äìqualitative study on the participants who have various prior experience with gaming and VR, and different levels of knowledge on the history presented within the virtual environment. This study investigates how participants accept and are stimulated in terms of personal experience and their expectations and ideas for the future of museums if VR is used for enhancing the learning of cultural heritage. Prior gaming and VR experience were investigated to see whether they do indeed influence the preference for using VR for learning cultural heritage. We demonstrated that particular age groups and background are especially agreeable to virtual reality as environments for learning and experiencing cultural heritage, regardless of their knowledge of the historical context of the virtually reconstructed site. Our findings also revealed important behaviours in our demographics group with regards to user preferred length of time and the believability of the virtual environment and how it influences aspects of their experience such as the exploration of the heritage site, familiarity, and meaning making. The study has implications for the use of VR for enhancing the experience of cultural heritage in museums and cultural institutions.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="Li2018MultiuserInteractionHybrid" class="col-sm-8"> <div class="title">Multiuser Interaction with Hybrid VR and AR for Cultural Heritage Objects</div> <div class="author"> <em>Yue Li<sup>*</sup></em>, Eugene Ch‚Äông, Shengdan Cai, and Simon See </div> <div class="periodical"> <em>In 2018 3rd Digital Heritage International Congress (DigitalHERITAGE) Held Jointly with 2018 24th International Conference on Virtual Systems &amp; Multimedia (VSMM 2018)</em>, Oct 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/DigitalHeritage.2018.8810126" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> </div> <div class="abstract hidden"> <p>This research investigates the factors and ways in which users initiate conversations and engage in interactions in a hybrid virtual environment using a combination of Virtual Reality (VR) and Augmented Reality (AR) devices. The research was done in the ‚Äòspirit of the ancient Silk Road‚Äô where trade brought in exchange of ideas, cultural influence and cross-border communications. The notion of a 21st century Silk Road is necessarily digital, over the Internet and based around 3D cultural heritage objects. Digi-Capital‚Äôs Report forecasts the revenue of AR and VR to be US$150b by 2020. We projected that VR and AR will become pervasive, much like the Social Web and the universal ubiquity of mobile devices such as smartphones and wearables. Here, we conducted a user study exploring users‚Äô acceptance of the use of hybrid VR and AR for cultural heritage, and investigated the social nature of multiple co-located user interaction. We adapted the UTAUT questionnaire in our experiment and found that social influence has positive effects on performance expectancy and effort expectancy, which generate positive effects on user behavioural intention. This study pioneers the future design and use of hybrid VR and AR technology in cultural heritage specifically, and in other application areas generally by highlighting the significant role that social influence plays in enhancing users‚Äô behavioural intention facilitated by different immersive devices.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="Wang2024MagicMapEnhancingIndoor" class="col-sm-8"> <div class="title">MagicMap: Enhancing Indoor Navigation Experience in VR Museums</div> <div class="author"> Xueqi Wang, <em>Yue Li<sup>*</sup></em>, and Hai-Ning Liang </div> <div class="periodical"> <em>In 2024 IEEE Conference Virtual Reality and 3D User Interfaces (VR)</em>, Mar 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/VR58804.2024.00107" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> </div> <div class="abstract hidden"> <p>Museum visitors are typically advised to follow trajectories planned by curators. Nevertheless, the diverse locomotion techniques available in Virtual Reality (VR) offer various navigation methods that are unattainable within physical museum spaces. Interestingly, these techniques have rarely been explored within museum settings. Our study aims to investigate appropriate navigation methods in VR museums. We first conducted a study in a virtual reconstruction of a local museum with the following navigation methods: a 2D minimap, a World-in-Miniature (WiM) system, and a WiM map. Our results showed that the WiM map with a point-and-select interaction technique outperformed the other two regarding ease of learning, reduced workload, lessened motion sickness, and greater user preferences. Based on the findings, we improved the WiM map and introduced MagicMap. It builds upon the WiM map and translates the curatorial principles of museum visiting into a hierarchical menu layout. Our further evaluation showed that MagicMap supported prolonged engagement in VR museums, enhanced system usability and overall user experience, and reduced users‚Äô perceived workload. Our findings have implications for the future design of navigation systems in VR museums and complex indoor environments.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="Wang2025ResponsiveViewEnhancing3D" class="col-sm-8"> <div class="title">ResponsiveView: Enhancing 3D Artifact Viewing Experience in VR Museums</div> <div class="author"> Xueqi Wang, <em>Yue Li<sup>*</sup></em>, Boge Ling, Han-Mei Chen, and Hai-Ning Liang </div> <div class="periodical"> <em>IEEE Transactions on Visualization and Computer Graphics</em>, May 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/TVCG.2025.3549872" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> </div> <div class="abstract hidden"> <p>The viewing experience of 3D artifacts in Virtual Reality (VR) museums is constrained and affected by various factors, such as pedestal height, viewing distance, and object scale. User experiences regarding these factors can vary subjectively, making it difficult to identify a universal optimal solution. In this paper, we collect empirical data on user-determined parameters for the optimal viewing experience in VR museums. By modeling users‚Äô viewing behaviors in VR museums, we derive predictive functions that configure the pedestal height, calculate the optimal viewing distance, and adjust the appropriate handheld scale for the optimal viewing experience. This led to our novel 3D responsive design, ResponsiveView. Similar to the responsive web design that automatically adjusts for different screen sizes, ResponsiveView automatically adjusts the parameters in the VR environment to facilitate users‚Äô viewing experience. The design has been validated with two popular inputs available in current commercial VR devices: controller-based interactions and hand tracking, demonstrating enhanced viewing experience in VR museums.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> </div> <div id="Xu2023CubeMuseumARTangible" class="col-sm-8"> <div class="title">CubeMuseum AR: A Tangible Augmented Reality Interface for Cultural Heritage Learning and Museum Gifting</div> <div class="author"> Ningning Xu, <em>Yue Li<sup>*</sup></em>, Xingbo Wei, Letian Xie, Lingyun Yu, and Hai-Ning Liang </div> <div class="periodical"> <em>International Journal of Human‚ÄìComputer Interaction</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1080/10447318.2023.2171350" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> </div> <div class="abstract hidden"> <p>Museum artifacts are the main way for visitors to experience and learn about cultural heritage. Augmented reality (AR) allows for high interactivity and is increasingly applied in museums to improve tourists‚Äô experience and learning. It also supports the extension of museum experience to outside of the physical museum space, contributing to the visiting trajectory and takeaway experience. In this paper, we present our design of two tangible AR interfaces for cultural artifacts: Postcard AR and CubeMuseum AR, followed by three user studies that evaluate and optimize the design. In Study 1, we conducted a within-subjects study (N \frac14 24) that compares the two AR interfaces with a baseline condition (Leaflet). Our results demonstrate the positive effects of tangible AR interfaces on users‚Äô motivation and engagement in learning cultural heritage. In Study 2, we further explored how to optimize CubeMuseum AR by adopting a user-centered design approach. Through the analysis of expert interviews (N \frac14 7) and an online survey (N \frac14 207), the results specify a series of requirements and design guidelines for tangible AR interfaces to be used as a learning tool and a hybrid gift. Based on the findings, the design of the CubeMuseum AR was optimized and evaluated in Study 3. A between-subjects user study was conducted (N \frac14 32) to compare the optimized design with the initial design. The results verified the positive effects of gamified tangible AR interfaces on users‚Äô motivation, engagement, and performance in learning cultural heritage. We present our design and evaluation results, and discuss the implications of designing tangible AR interfaces for cultural heritage learning and museum gifting.</p> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="https://www.linkedin.com/in/imyueli" title="Linkedin username" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="mailto:imyueli@gmail.com" title="Email"><i class="fa-solid fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=1MFLouMAAAAJ" title="Scholar userid" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://www.researchgate.net/profile/Yue-Li-186/" title="Research gate profile" rel="external nofollow noopener" target="_blank"><i class="ai ai-researchgate"></i></a> <a href="https://github.com/imyueli" title="Github username" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://orcid.org/0000-0003-3728-218X" title="Orcid id" rel="external nofollow noopener" target="_blank"><i class="ai ai-orcid"></i></a> </div> <div class="contact-note">@imYueLi </div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> ¬© Copyright 2026 Yue Li. All Rights Reserved. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?v=f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?v=a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>